{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c371bded",
   "metadata": {},
   "source": [
    "### Have being facing challenges regarding training CNN and other DL models. Want to rule out if a particular loss fucntion plays the role in making binary classification very difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d65ed",
   "metadata": {},
   "source": [
    "## 1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4a8f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sys, nltk, re, bs4, sklearn, matplotlib\n",
    "from bs4 import BeautifulSoup\n",
    "import datasets, transformers \n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download(\"stopwords\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7a52b5",
   "metadata": {},
   "source": [
    "## 2. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c21b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 380, 'name': 'YouTube Spam Collection', 'repository_url': 'https://archive.ics.uci.edu/dataset/380/youtube+spam+collection', 'data_url': 'https://archive.ics.uci.edu/static/public/380/data.csv', 'abstract': 'It is a public set of comments collected for spam research. It has five datasets composed by 1,956 real messages extracted from five videos that were among the 10 most viewed on the collection period.', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Text'], 'num_instances': 1956, 'num_features': 3, 'feature_types': [], 'demographics': [], 'target_col': ['CLASS'], 'index_col': ['VIDEO', 'COMMENT_ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2015, 'last_updated': 'Wed Apr 03 2024', 'dataset_doi': '10.24432/C58885', 'creators': ['T.C. Alberto', 'J.V. Lochter'], 'intro_paper': None, 'additional_info': {'summary': 'The table below lists the datasets, the YouTube video ID, the amount of samples in each class and the total number of samples per dataset.\\r\\n\\r\\nDataset --- YouTube ID -- # Spam - # Ham - Total\\r\\nPsy ------- 9bZkp7q19f0 --- 175 --- 175 --- 350\\r\\nKatyPerry - CevxZvSJLk8 --- 175 --- 175 --- 350\\r\\nLMFAO ----- KQ6zr6kCPj8 --- 236 --- 202 --- 438\\r\\nEminem ---- uelHwf8o7_U --- 245 --- 203 --- 448\\r\\nShakira --- pRpeEdMmmQ0 --- 174 --- 196 --- 370\\r\\n\\r\\nNote: the chronological order of the comments were kept.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The collection is composed by one CSV file per dataset, where each line has the following attributes:\\r\\n\\r\\nCOMMENT_ID,AUTHOR,DATE,CONTENT,TAG\\r\\n\\r\\nWe offer one example bellow:\\r\\n\\r\\nz12oglnpoq3gjh4om04cfdlbgp2uepyytpw0k,Francisco Nora,2013-11-28T19:52:35,please like :D https://premium.easypromosapp.com/voteme/19924/616375350,1\\r\\n', 'citation': None}}\n",
      "         name     role         type demographic description units  \\\n",
      "0       VIDEO       ID  Categorical        None        None  None   \n",
      "1  COMMENT_ID       ID  Categorical        None        None  None   \n",
      "2      AUTHOR  Feature  Categorical        None        None  None   \n",
      "3        DATE  Feature  Categorical        None        None  None   \n",
      "4     CONTENT  Feature  Categorical        None        None  None   \n",
      "5       CLASS   Target       Binary        None        None  None   \n",
      "\n",
      "  missing_values  \n",
      "0             no  \n",
      "1             no  \n",
      "2             no  \n",
      "3             no  \n",
      "4             no  \n",
      "5             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "youtube_spam_collection = fetch_ucirepo(id=380) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = youtube_spam_collection.data.features \n",
    "y = youtube_spam_collection.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(youtube_spam_collection.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(youtube_spam_collection.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad5e90",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597125bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Ashutosh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "C:\\Users\\Ashutosh\\AppData\\Local\\Temp\\ipykernel_32736\\1396520400.py:11: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  X_all = [BeautifulSoup(i, \"html.parser\").get_text() for i in X_all]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "# We want to remove URL as comment as it will confuse the model but we will keep a flag that a url watch present here, \n",
    "#as it might be a strong indicator of a spam comment\n",
    "\n",
    "X_all = [re.sub(r'http\\S+|www\\S+|https\\S+', 'url', i, flags=re.MULTILINE) for i in X['CONTENT']]\n",
    "\n",
    "# Similarly for watch, we will remove complext suffix but keep the word watch as an input to out model\n",
    "X_all = [re.sub(r'watch\\?v=\\S+', 'watch', i, flags=re.MULTILINE) for i in X_all]\n",
    "\n",
    "# Remove any html tags by mistake\n",
    "X_all = [BeautifulSoup(i, \"html.parser\").get_text() for i in X_all]\n",
    "\n",
    "# for any emoji or emoticon replace it with the word \"emoji\" as it can be a useful feature\n",
    "X_all = [re.sub(\"[:;][)|(DP]\",\"emoji\",i) for i in X_all]\n",
    "\n",
    "# any number does not look like year should be replaced with an identifier number\n",
    "\n",
    "def not_number(string):\n",
    "    string = re.sub(\",\",\"\",string)\n",
    "    try:\n",
    "        float(string)\n",
    "        return False\n",
    "    except ValueError:\n",
    "        return True\n",
    "    \n",
    "def check_range(string_no):\n",
    "    string_no = re.sub(\",\",\"\",string_no)\n",
    "    if(float(string_no) <= 2100.0 and float(string_no) >= 1800.0):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)\n",
    "\n",
    "def remove_suprious_num(snt):\n",
    "    token_words = word_tokenize(snt)\n",
    "    changed_words = [i if not_number(i) else \"year\" if  check_range(i) else \"large number\" for i in token_words]\n",
    "    return(\" \".join(changed_words))\n",
    "\n",
    "X_all = [remove_suprious_num(i) for i in X_all]\n",
    "\n",
    "# convert all to lower case\n",
    "X_all = [i.casefold() for i in X_all]\n",
    "\n",
    "# romve extra white space \n",
    "X_all = [re.sub(r'[^\\w\\s]', '', i) for i in X_all]\n",
    "\n",
    "X_all = [re.sub(r'\\s+', ' ', i).strip() for i in X_all]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad89d829",
   "metadata": {},
   "source": [
    "## 4. Split into test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8072d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use y to stratify so the distribution of labels is simialr in training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8afc7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<WordListCorpusReader in '.../corpora/stopwords' (not loaded yet)>\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0df95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(sent):\n",
    "    token_words = word_tokenize(sent)\n",
    "    clean_token_words = [i for i in token_words if i not in stop_words]\n",
    "    return(\" \".join(clean_token_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b95e991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video large number views large number million people earth',\n",
       " 'head like large number years ago time flies',\n",
       " 'large number billions year',\n",
       " 'wtf subscribe channel thanx emoji',\n",
       " 'omg',\n",
       " 'please become first subscriber thank',\n",
       " 'everyone come check new gta large number gameplay right watch',\n",
       " 'remember back popular everyone school shuffling crazy',\n",
       " 'url please halp project',\n",
       " 'haha funny see salt westerners top views youtube goes video dont even understand keep salt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [remove_stop_words(i) for i in X_train]\n",
    "X_test = [remove_stop_words(i) for i in X_test]\n",
    "X_train[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa9462e",
   "metadata": {},
   "source": [
    "### 5b. Normalization - Lemmization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da21fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video large number view large number million people earth',\n",
       " 'head like large number year ago time fly',\n",
       " 'large number billion year',\n",
       " 'wtf subscribe channel thanx emoji',\n",
       " 'omg',\n",
       " 'please become first subscriber thank',\n",
       " 'everyone come check new gta large number gameplay right watch',\n",
       " 'remember back popular everyone school shuffling crazy',\n",
       " 'url please halp project',\n",
       " 'haha funny see salt westerner top view youtube go video dont even understand keep salt',\n",
       " 'believe jesus christ savior sin truly believe jesus christ savior sin go heaven believe jesus christ saved salvation gained god righteousness matter much sinned past present especially future believe jesus christ savior go heaven forever whole truth spread truth',\n",
       " 'music hero',\n",
       " 'check berzerk video channel emoji',\n",
       " 'check app solve partydrunk problem href url',\n",
       " 'love song make wan na dance',\n",
       " 'love song',\n",
       " 'check video youtube',\n",
       " 'check video youtube href url eminem ft rihanna love way lie',\n",
       " 'absolutely adore watching football plus started earning income risk claiming bonus deal weird technique put money something one bookmaker put money betfair acquire bonus income lad named jim vanstone selecting wager free website vanstone secret google generated large number quid far free assume bookmaker pay get new men woman succeeds',\n",
       " 'medium evil please see share w w w farrell report net top ex uk police intelligence analyst turned whistleblower tony farrell expose horrific monstrous coverup perpetrated criminal operating crime inside mainstream entertainment medium law firm beware protect child devil brutally target innocent people real criminal linked london 77 attack year must see make viral also see uk column video 31st january year']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_data(sent,lemmitizer):\n",
    "    token_words = word_tokenize(sent)\n",
    "    clean_tokens = [lemmitizer.lemmatize(i) for i in token_words]\n",
    "    return(\" \".join(clean_tokens)) \n",
    "\n",
    "lemmitizer = WordNetLemmatizer()\n",
    "X_train = [normalize_data(i,lemmitizer) for i in X_train]\n",
    "X_test = [normalize_data(i,lemmitizer) for i in X_test]\n",
    "X_train[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5cd9f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# fit data to tfidf\n",
    "train_tfidf = tfidf.fit_transform(X_train)\n",
    "test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c743c53f",
   "metadata": {},
   "source": [
    "### Training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc14844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1564, 2957])\n"
     ]
    }
   ],
   "source": [
    "X_tensor_train = torch.tensor(train_tfidf.toarray(), dtype=torch.float32)    \n",
    "print(X_tensor_train.shape)\n",
    "\n",
    "y_tensor_train = torch.tensor(np.array(y_train), dtype=torch.float32)\n",
    "\n",
    "dataset_train = TensorDataset(X_tensor_train, y_tensor_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=10, shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eebfed",
   "metadata": {},
   "source": [
    "### Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77745c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([392, 2957])\n"
     ]
    }
   ],
   "source": [
    "X_tensor_test = torch.tensor(test_tfidf.toarray(), dtype=torch.float32)    \n",
    "print(X_tensor_test.shape)\n",
    "y_tensor_test = torch.tensor(np.array(y_test), dtype=torch.float32)\n",
    "\n",
    "dataset_test = TensorDataset(X_tensor_test, y_tensor_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=10, shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd97b4",
   "metadata": {},
   "source": [
    "# Simple ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a17be3",
   "metadata": {},
   "source": [
    "# 1. Sigmoid and BCE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5aa9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Define model\n",
    "class SpamFilter(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SpamFilter, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_features=input_size,\n",
    "                               out_features=128)\n",
    "        \n",
    "        self.layer2 = nn.Linear(in_features=128,\n",
    "                               out_features=64 )\n",
    "        \n",
    "        self.layer3 = nn.Linear(in_features=64,\n",
    "                               out_features=1 )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.layer1(x))\n",
    "        out = torch.relu(self.layer2(out))\n",
    "        out = torch.sigmoid(self.layer3(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39b5af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input_size = train_tfidf.shape[1]\n",
    "model0 = SpamFilter(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "460a7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(params=model0.parameters(),\n",
    "                            lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd8bcd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 72.09758307412267\n",
      "Epoch 2/10, Loss: 14.634043395984918\n",
      "Epoch 3/10, Loss: 5.122163700521924\n",
      "Epoch 4/10, Loss: 2.1478996443911456\n",
      "Epoch 5/10, Loss: 1.0356194037303794\n",
      "Epoch 6/10, Loss: 0.5053162984258961\n",
      "Epoch 7/10, Loss: 0.2893129837138986\n",
      "Epoch 8/10, Loss: 0.18719634010631125\n",
      "Epoch 9/10, Loss: 0.1258652334827275\n",
      "Epoch 10/10, Loss: 0.08948239286382886\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model0.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model0(inputs)\n",
    "        loss = criterion(outputs, labels)        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "     \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa1b520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuarcy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model0.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "train_preds = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for inputs, labels in dataloader_train:\n",
    "        outputs = model0(inputs)\n",
    "        labels = np.array(labels.squeeze(dim=1))\n",
    "        predicted = np.array((outputs > 0.5).float())\n",
    "        predicted = np.array([item[0] for item in predicted])\n",
    "        total += len(labels)\n",
    "        \n",
    "        cor = predicted == labels\n",
    "        train_preds_temp =  [float(b) for b in predicted]\n",
    "        train_preds.extend(train_preds_temp)\n",
    "        correct += cor.sum()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Test Accuarcy: {:.2f}%'.format(100 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01b880d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuarcy: 92.60%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model0.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader_test:\n",
    "        outputs = model0(inputs)\n",
    "        labels = np.array(labels.squeeze(dim=1))\n",
    "        predicted = np.array((outputs > 0.5).float())\n",
    "        predicted = np.array([item[0] for item in predicted])\n",
    "        total += len(labels)\n",
    "        \n",
    "        cor = predicted == labels\n",
    "        \n",
    "        test_preds_temp =  [float(b) for b in predicted]\n",
    "        test_preds.extend(test_preds_temp)\n",
    "        \n",
    "        correct += cor.sum()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Test Accuarcy: {:.2f}%'.format(100 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "747003ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy is 1.0\n",
      "test accuracy is 0.926\n",
      "training precision is 1.0\n",
      "test precision is 0.922\n",
      "training recall is 1.0\n",
      "test recall is 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       191\n",
      "           1       0.92      0.94      0.93       201\n",
      "\n",
      "    accuracy                           0.93       392\n",
      "   macro avg       0.93      0.93      0.93       392\n",
      "weighted avg       0.93      0.93      0.93       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "ann_train_accuracy = accuracy_score(y_train, train_preds)\n",
    "# Testing accuracy\n",
    "ann_test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "ann_train_precision = precision_score(y_train, train_preds)\n",
    "ann_test_precision = precision_score(y_test, test_preds)\n",
    "\n",
    "ann_train_recall = recall_score(y_train, train_preds)\n",
    "ann_test_recall = recall_score(y_test, test_preds)\n",
    "\n",
    "print(\"training accuracy is {0}\".format(round(ann_train_accuracy,3)))\n",
    "print(\"test accuracy is {0}\".format(round(ann_test_accuracy,3)))\n",
    "\n",
    "print(\"training precision is {0}\".format(round(ann_train_precision,3)))\n",
    "print(\"test precision is {0}\".format(round(ann_test_precision,3)))\n",
    "\n",
    "print(\"training recall is {0}\".format(round(ann_train_recall,3)))\n",
    "print(\"test recall is {0}\".format(round(ann_test_recall,3)))\n",
    "\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bc437e",
   "metadata": {},
   "source": [
    "# 2. BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60cedbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "del total,\n",
    "del train_preds,\n",
    "del accuracy,\n",
    "del ann_train_accuracy\n",
    "del ann_test_accuracy ,\n",
    "del ann_train_precision, \n",
    "del ann_test_precision,\n",
    "del ann_train_recall ,\n",
    "del ann_test_recall,\n",
    "del running_loss,\n",
    "del optimizer,\n",
    "del criterion\n",
    "del model0,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ced1ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Define model\n",
    "class SpamFilter2(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SpamFilter2, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_features=input_size,\n",
    "                               out_features=128)\n",
    "        \n",
    "        self.layer2 = nn.Linear(in_features=128,\n",
    "                               out_features=64 )\n",
    "        \n",
    "        self.layer3 = nn.Linear(in_features=64,\n",
    "                               out_features=1 )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.layer1(x))\n",
    "        out = torch.relu(self.layer2(out))\n",
    "        out = self.layer3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45fc8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = SpamFilter2(input_size)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(params=model0.parameters(),\n",
    "                            lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca7199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65925980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 71.21296524628997\n",
      "Epoch 2/10, Loss: 14.409506441093981\n",
      "Epoch 3/10, Loss: 5.220782635151409\n",
      "Epoch 4/10, Loss: 2.0344197752710897\n",
      "Epoch 5/10, Loss: 0.9388499096094165\n",
      "Epoch 6/10, Loss: 0.4932650767368614\n",
      "Epoch 7/10, Loss: 0.3007843071682146\n",
      "Epoch 8/10, Loss: 0.20007469480697182\n",
      "Epoch 9/10, Loss: 0.13719925464101834\n",
      "Epoch 10/10, Loss: 0.09928184779982985\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model0.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model0(inputs)\n",
    "        loss = criterion(outputs, labels)        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "     \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dee38814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuarcy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model0.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "train_preds = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for inputs, labels in dataloader_train:\n",
    "        logits = model0(inputs)\n",
    "        outputs = torch.sigmoid(logits)\n",
    "        labels = np.array(labels.squeeze(dim=1))\n",
    "        predicted = np.array((outputs > 0.5).float())\n",
    "        predicted = np.array([item[0] for item in predicted])\n",
    "        total += len(labels)\n",
    "        \n",
    "        cor = predicted == labels\n",
    "        train_preds_temp =  [float(b) for b in predicted]\n",
    "        train_preds.extend(train_preds_temp)\n",
    "        correct += cor.sum()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Test Accuarcy: {:.2f}%'.format(100 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "706ac4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuarcy: 92.60%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model0.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader_test:\n",
    "        logits = model0(inputs)\n",
    "        outputs = torch.sigmoid(logits)\n",
    "        labels = np.array(labels.squeeze(dim=1))\n",
    "        predicted = np.array((outputs > 0.5).float())\n",
    "        predicted = np.array([item[0] for item in predicted])\n",
    "        total += len(labels)\n",
    "        \n",
    "        cor = predicted == labels\n",
    "        \n",
    "        test_preds_temp =  [float(b) for b in predicted]\n",
    "        test_preds.extend(test_preds_temp)\n",
    "        \n",
    "        correct += cor.sum()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Test Accuarcy: {:.2f}%'.format(100 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4365c07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy is 1.0\n",
      "test accuracy is 0.926\n",
      "training precision is 1.0\n",
      "test precision is 0.917\n",
      "training recall is 1.0\n",
      "test recall is 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92       191\n",
      "           1       0.92      0.94      0.93       201\n",
      "\n",
      "    accuracy                           0.93       392\n",
      "   macro avg       0.93      0.93      0.93       392\n",
      "weighted avg       0.93      0.93      0.93       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "ann_train_accuracy = accuracy_score(y_train, train_preds)\n",
    "# Testing accuracy\n",
    "ann_test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "ann_train_precision = precision_score(y_train, train_preds)\n",
    "ann_test_precision = precision_score(y_test, test_preds)\n",
    "\n",
    "ann_train_recall = recall_score(y_train, train_preds)\n",
    "ann_test_recall = recall_score(y_test, test_preds)\n",
    "\n",
    "print(\"training accuracy is {0}\".format(round(ann_train_accuracy,3)))\n",
    "print(\"test accuracy is {0}\".format(round(ann_test_accuracy,3)))\n",
    "\n",
    "print(\"training precision is {0}\".format(round(ann_train_precision,3)))\n",
    "print(\"test precision is {0}\".format(round(ann_test_precision,3)))\n",
    "\n",
    "print(\"training recall is {0}\".format(round(ann_train_recall,3)))\n",
    "print(\"test recall is {0}\".format(round(ann_test_recall,3)))\n",
    "\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caf4224",
   "metadata": {},
   "source": [
    "# Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3495ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "del total,\n",
    "del train_preds,\n",
    "del accuracy,\n",
    "del ann_train_accuracy\n",
    "del ann_test_accuracy ,\n",
    "del ann_train_precision, \n",
    "del ann_test_precision,\n",
    "del ann_train_recall ,\n",
    "del ann_test_recall,\n",
    "del running_loss,\n",
    "del optimizer,\n",
    "del criterion\n",
    "del model0,correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af3532",
   "metadata": {},
   "source": [
    "## Labels for Cross Entropy should be long not float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1ec4c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1564, 2957])\n",
      "torch.Size([392, 2957])\n"
     ]
    }
   ],
   "source": [
    "X_tensor_train = torch.tensor(train_tfidf.toarray(), dtype=torch.float32)    \n",
    "print(X_tensor_train.shape)\n",
    "\n",
    "y_tensor_train = torch.tensor(np.array(y_train), dtype=torch.long)\n",
    "\n",
    "dataset_train = TensorDataset(X_tensor_train, y_tensor_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=10, shuffle=False,drop_last=False)\n",
    "\n",
    "X_tensor_test = torch.tensor(test_tfidf.toarray(), dtype=torch.float32)    \n",
    "print(X_tensor_test.shape)\n",
    "y_tensor_test = torch.tensor(np.array(y_test), dtype=torch.long)\n",
    "\n",
    "dataset_test = TensorDataset(X_tensor_test, y_tensor_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=10, shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0af8e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Define model\n",
    "class SpamFilter3(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SpamFilter3, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_features=input_size,\n",
    "                               out_features=128)\n",
    "        \n",
    "        self.layer2 = nn.Linear(in_features=128,\n",
    "                               out_features=64 )\n",
    "        \n",
    "        self.layer3 = nn.Linear(in_features=64,\n",
    "                               out_features=2 )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.layer1(x))\n",
    "        out = torch.relu(self.layer2(out))\n",
    "        out = self.layer3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c6db64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = SpamFilter3(input_size)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(params=model0.parameters(),\n",
    "                            lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6e4db7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 65.81644764356315\n",
      "Epoch 2/10, Loss: 12.661946819978766\n",
      "Epoch 3/10, Loss: 4.234536151168868\n",
      "Epoch 4/10, Loss: 1.6042365015746327\n",
      "Epoch 5/10, Loss: 0.7014152535411995\n",
      "Epoch 6/10, Loss: 0.3257722453381575\n",
      "Epoch 7/10, Loss: 0.18567115622317942\n",
      "Epoch 8/10, Loss: 0.11333005322194367\n",
      "Epoch 9/10, Loss: 0.07111655594144395\n",
      "Epoch 10/10, Loss: 0.04413262372054305\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model0.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model0(inputs)\n",
    "        #print(outputs)\n",
    "        #print(labels.squeeze(1).shape)\n",
    "        loss = criterion(outputs, labels.squeeze(1))        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "     \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc930565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuarcy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model0.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "train_preds = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for inputs, labels in dataloader_train:\n",
    "        logits = model0(inputs)\n",
    "        #print(logits)\n",
    "        outputs = torch.argmax(logits, dim=1)\n",
    "        #print(outputs)\n",
    "        labels = np.array(labels.squeeze(dim=1))\n",
    "        #predicted = np.array((outputs > 0.5).float())\n",
    "        predicted = np.array([item for item in np.array(outputs)])\n",
    "        total += len(labels)\n",
    "        \n",
    "        cor = predicted == labels\n",
    "        train_preds_temp =  [float(b) for b in predicted]\n",
    "        train_preds.extend(train_preds_temp)\n",
    "        correct += cor.sum()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Test Accuarcy: {:.2f}%'.format(100 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e48082db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuarcy: 93.11%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model0.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader_test:\n",
    "        #print(inputs)\n",
    "        logits = model0(inputs)\n",
    "        #print(logits)\n",
    "        outputs = torch.argmax(logits,dim= 1)\n",
    "        #print(\"this output\")\n",
    "        #print(outputs)\n",
    "        labels = np.array(labels.squeeze(dim=1))\n",
    "        #print(outputs)\n",
    "        #predicted = np.array((outputs > 0.5).float())\n",
    "        predicted = np.array([item for item in np.array(outputs)])\n",
    "        total += len(labels)\n",
    "        \n",
    "        cor = predicted == labels\n",
    "        \n",
    "        test_preds_temp =  [float(b) for b in predicted]\n",
    "        test_preds.extend(test_preds_temp)\n",
    "        \n",
    "        correct += cor.sum()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Test Accuarcy: {:.2f}%'.format(100 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2138dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy is 1.0\n",
      "test accuracy is 0.931\n",
      "training precision is 1.0\n",
      "test precision is 0.922\n",
      "training recall is 1.0\n",
      "test recall is 0.945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       191\n",
      "           1       0.92      0.95      0.93       201\n",
      "\n",
      "    accuracy                           0.93       392\n",
      "   macro avg       0.93      0.93      0.93       392\n",
      "weighted avg       0.93      0.93      0.93       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "ann_train_accuracy = accuracy_score(y_train, train_preds)\n",
    "# Testing accuracy\n",
    "ann_test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "ann_train_precision = precision_score(y_train, train_preds)\n",
    "ann_test_precision = precision_score(y_test, test_preds)\n",
    "\n",
    "ann_train_recall = recall_score(y_train, train_preds)\n",
    "ann_test_recall = recall_score(y_test, test_preds)\n",
    "\n",
    "print(\"training accuracy is {0}\".format(round(ann_train_accuracy,3)))\n",
    "print(\"test accuracy is {0}\".format(round(ann_test_accuracy,3)))\n",
    "\n",
    "print(\"training precision is {0}\".format(round(ann_train_precision,3)))\n",
    "print(\"test precision is {0}\".format(round(ann_test_precision,3)))\n",
    "\n",
    "print(\"training recall is {0}\".format(round(ann_train_recall,3)))\n",
    "print(\"test recall is {0}\".format(round(ann_test_recall,3)))\n",
    "\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d7b473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf505595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
